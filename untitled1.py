# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1itkeM3QuNf0AXBQI2SE34V63p6CqzqQw
"""

Nice — let's dive in. I’ll teach you CGANs (Conditional GANs) with MLPs using TensorFlow across 15 focused Python programs. Today you get **Session 1 — Foundations**: three conceptual paragraphs, a clear, runnable TensorFlow MLP CGAN that generates simple 2D conditioned samples, plus practical hacks and a short daily assignment to cement learning.

# Concepts (3 short paragraphs)

A **Conditional GAN (CGAN)** is an extension of the vanilla GAN where both the generator and discriminator receive an extra input: a condition (typically a class label or some side information). Instead of modeling $p(x)$ only, a CGAN models $p(x \mid y)$. Conditioning lets the generator produce samples specific to a class (e.g., generate digits conditioned on the label "7") and helps stabilize / guide learning when you want class-aware generation.

Architecturally, conditioning can be implemented by concatenating the label representation with the noise vector at the generator input and likewise concatenating the label with the real/fake sample input to the discriminator. For discrete labels you can use one-hot vectors; for more complex or sparse labels, learn a small embedding. With MLPs (fully connected nets) this concatenation is simple and effective for low-dimensional data or when modelling flattened feature vectors.

Training follows the same adversarial loop as a GAN: alternate training the discriminator to distinguish real conditioned samples from generated conditioned samples, then train the generator to fool the discriminator *when the condition is applied*. Losses can be the standard binary cross-entropy, but many improvements (WGAN, hinge loss, label smoothing) exist — we'll use BCE for clarity in early sessions and explore advanced losses later.

# Session 1 — Program 1: Simple MLP CGAN (2D points conditioned on label)

Goal: build a tiny CGAN that learns two Gaussian clusters conditioned on class label 0 or 1. This gives a clear visualization of conditioning and the adversarial game.

Copy-paste and run (requires `tensorflow>=2.3`, `numpy`, `matplotlib`):

```python
# cgan_mlp_session1.py
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model
import matplotlib.pyplot as plt

# --- Data: two 2D Gaussian clusters, labels 0 or 1 ---
def make_conditional_2d_data(n_per_class=1000, seed=0):
    np.random.seed(seed)
    # class 0: centered at (-2, 0)
    x0 = np.random.randn(n_per_class, 2) * 0.4 + np.array([-2.0, 0.0])
    y0 = np.zeros((n_per_class, 1), dtype=np.int32)
    # class 1: centered at (+2, 0)
    x1 = np.random.randn(n_per_class, 2) * 0.4 + np.array([2.0, 0.0])
    y1 = np.ones((n_per_class, 1), dtype=np.int32)
    X = np.vstack([x0, x1]).astype(np.float32)
    Y = np.vstack([y0, y1]).astype(np.int32)
    # shuffle
    perm = np.random.permutation(len(X))
    return X[perm], Y[perm]

# --- Model building helpers ---
def build_generator(latent_dim=8, label_dim=1, hidden=64):
    # label_dim is size of one-hot or embedding; for simplicity we'll use one-hot (2 classes)
    noise_input = layers.Input(shape=(latent_dim,), name='noise')
    label_input = layers.Input(shape=(2,), name='label')  # one-hot for 2 classes
    x = layers.Concatenate()([noise_input, label_input])
    x = layers.Dense(hidden, activation='relu')(x)
    x = layers.Dense(hidden, activation='relu')(x)
    out = layers.Dense(2, activation=None)(x)  # 2D output
    return Model([noise_input, label_input], out, name='generator')

def build_discriminator(label_dim=1, hidden=64):
    sample_input = layers.Input(shape=(2,), name='sample')
    label_input = layers.Input(shape=(2,), name='label')  # one-hot
    x = layers.Concatenate()([sample_input, label_input])
    x = layers.Dense(hidden, activation='relu')(x)
    x = layers.Dense(hidden, activation='relu')(x)
    out = layers.Dense(1, activation='sigmoid')(x)
    return Model([sample_input, label_input], out, name='discriminator')

# --- Training setup ---
def one_hot_labels(labels, num_classes=2):
    return tf.one_hot(labels.flatten(), depth=num_classes)

def train_cgan(epochs=1000, batch_size=128, latent_dim=8, print_every=100):
    # data
    X, Y = make_conditional_2d_data(n_per_class=1000)
    dataset = tf.data.Dataset.from_tensor_slices((X, Y)).shuffle(2000).batch(batch_size)

    # models
    gen = build_generator(latent_dim=latent_dim)
    disc = build_discriminator()

    # optimizers and losses
    g_opt = tf.keras.optimizers.Adam(1e-4)
    d_opt = tf.keras.optimizers.Adam(1e-4)
    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)

    # training loop
    @tf.function
    def d_step(real_samples, real_labels):
        real_labels_oh = tf.one_hot(real_labels[:,0], depth=2)
        batch = tf.shape(real_samples)[0]
        noise = tf.random.normal((batch, latent_dim))
        fake = gen([noise, real_labels_oh], training=True)

        with tf.GradientTape() as tape:
            real_out = disc([real_samples, real_labels_oh], training=True)
            fake_out = disc([fake, real_labels_oh], training=True)
            d_loss_real = bce(tf.ones_like(real_out), real_out)
            d_loss_fake = bce(tf.zeros_like(fake_out), fake_out)
            d_loss = d_loss_real + d_loss_fake
        grads = tape.gradient(d_loss, disc.trainable_variables)
        d_opt.apply_gradients(zip(grads, disc.trainable_variables))
        return d_loss

    @tf.function
    def g_step(batch_labels_oh):
        batch = tf.shape(batch_labels_oh)[0]
        noise = tf.random.normal((batch, latent_dim))
        with tf.GradientTape() as tape:
            fake = gen([noise, batch_labels_oh], training=True)
            fake_out = disc([fake, batch_labels_oh], training=True)
            g_loss = bce(tf.ones_like(fake_out), fake_out)
        grads = tape.gradient(g_loss, gen.trainable_variables)
        g_opt.apply_gradients(zip(grads, gen.trainable_variables))
        return g_loss

    # training
    for epoch in range(1, epochs+1):
        d_losses = []
        g_losses = []
        for real_samples, real_labels in dataset:
            d_loss = d_step(real_samples, real_labels)
            # For generator step we'll sample labels from the batch
            labels_oh = tf.one_hot(real_labels[:,0], depth=2)
            g_loss = g_step(labels_oh)
            d_losses.append(d_loss.numpy())
            g_losses.append(g_loss.numpy())

        if epoch % print_every == 0 or epoch == 1:
            print(f"Epoch {epoch:04d}: d_loss={np.mean(d_losses):.4f}, g_loss={np.mean(g_losses):.4f}")
            # visualize small grid
            visualize_generation(gen, latent_dim)

    return gen, disc

# --- Utility: visualize generator outputs for each label ---
def visualize_generation(gen, latent_dim, n_samples=200):
    # generate for label 0 and 1
    z = tf.random.normal((n_samples, latent_dim))
    labels0 = tf.one_hot(np.zeros(n_samples, dtype=int), depth=2)
    labels1 = tf.one_hot(np.ones(n_samples, dtype=int), depth=2)
    s0 = gen([z, labels0], training=False).numpy()
    s1 = gen([z, labels1], training=False).numpy()

    plt.figure(figsize=(6,3))
    plt.subplot(1,2,1)
    plt.scatter(s0[:,0], s0[:,1], alpha=0.6, s=5)
    plt.title("Generated cond=0")
    plt.subplot(1,2,2)
    plt.scatter(s1[:,0], s1[:,1], alpha=0.6, s=5)
    plt.title("Generated cond=1")
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    gen, disc = train_cgan(epochs=800, batch_size=128, latent_dim=8, print_every=200)
    # final visualization
    visualize_generation(gen, latent_dim=8)
```

# What to expect

* The generator learns to produce two distinct 2D clusters depending on the condition (label 0 vs 1). After enough epochs you should see two separate clouds roughly centered near the real data centers (-2, 0) and (+2, 0).
* Training may be noisy; losses won't monotonically decrease — judge by sample quality rather than loss alone.

# Hacks & tips (practical tricks)

1. **Start simple**: small latent dim (4–16) and small MLP sizes. Visualize often (every N epochs).
2. **Conditioning tricks**: try concatenating label to intermediate layers (not just input) or learn an embedding for labels and concatenate that — sometimes stabilizes.
3. **Label smoothing**: replace real-label 1.0 with 0.9 for discriminator real labels to help stability.
4. **Balanced batches**: ensure batch contains diverse labels each step (we used batch labels from real batch). For strict control, sample an equal number per label.
5. **Monitor samples, not just loss**: adversarial training has uninformative loss curves; visualize frequently.
6. **Reproducibility**: set seeds for NumPy and TF when debugging.

# Daily assignment — Session 1

1. Run the code as-is and produce the visualization (800 epochs). Save two screenshots: early (epoch 1) and late (final).
2. Modify latent\_dim to 2 and re-run — observe how much diversity the generator can encode with only 2D noise. Note differences.
3. Replace one-hot labels with a tiny learned embedding (use `layers.Embedding(2, 4)` then flatten) and compare training stability and sample quality. Write a 1-paragraph note on which looked better and why.
4. Push one small change to the architecture: either add a hidden layer, change activation to `leaky_relu`, or use `tanh` on the generator output — run and record observations.

Deliverable: paste your trained sample plots (or a short summary of observations) in the next message and I’ll critique and suggest precise improvements for Session 2.

---

Ready for Session 2 plan after you finish this? I’ll move from toy 2D data to conditional MNIST using MLPs, then to convolutional CGANs, loss variants, conditioning strategies, and finally advanced tricks and evaluation metrics across 15 sessions.